<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Statistical Physics and Machine Learning (PSL Weeks 2023/2024) | Statistical Physics and Machine Learning</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="/assets/css/style.css">
</head>
<body>
  


<nav class="navbar">
  <a class="nav-title" href="/">PSL Week StatPhys&ML</a>

  <div class="nav-links">
    <div class="dropdown">
      <button class="dropbtn">Past Editions ▾</button>
      <div class="dropdown-content">
        
          
            <a class="active" href="/editions/2025-2026/">2025-2026 (current)</a>
          
        
          
            <a href="/editions/2024-2025/">2024/2025</a>
          
        
          
            <a href="/editions/2023-2024/">2023/2024</a>
          
        
          
            <a href="/editions/2022-2023/">2022/2023</a>
          
        
      </div>
    </div>
  </div>
</nav>

  <main class="container">
    <h1 id="20232024-psl-week-on-statistical-physics-and-machine-learning">2023/2024 PSL Week on <em>Statistical Physics and Machine Learning</em></h1>

<p>The objective of the intensive week on machine learning and statistical physics is to present methods, ideas, and connections between these two fields. Indeed, the methods and ideas developed in the statistical physics of disordered systems can provide new tools for analyzing high-dimensional non-convex problems that arise in machine learning.</p>

<p>During the first part of the week, after a general introduction, we will focus on simple machine learning problems and analyze them using a statistical physics method that is rigorous and exact (though mathematically non-rigorous). This will allow us to concretely present some of the connections between machine learning and statistical physics. In particular, we will introduce the replica method, which has proven extremely useful in physics and other branches of science, as illustrated by the 2021 Nobel Prize in Physics awarded to Giorgio Parisi.</p>

<p>The second part will be devoted to more realistic models and current research questions, such as the Double Descent phenomenon and convex and non-convex optimization.</p>

<h2 id="course-information">Course Information</h2>

<ul>
  <li><strong>Instructors</strong>: <a href="https://www.di.ens.fr/~fbach/">Francis Bach</a> (INRIA &amp; DI-ENS), <a href="https://www.lpens.ens.psl.eu/giulio-biroli/">Giulio Biroli</a> (LPENS), <a href="https://brloureiro.github.io/">Bruno Loureiro</a> (CNRS &amp; DI-ENS).</li>
  <li><strong>Dates</strong>: 04-08 March, 2024</li>
  <li><strong>Location</strong>: See PSL ENT or contact us.</li>
</ul>

<h2 id="evaluation">Evaluation</h2>

<p>Assiduity + Paper review.</p>

<h2 id="course-description">Course Description</h2>

<ul>
  <li>Introduction to Machine Learning.</li>
  <li>Introduction to Statistical Physics.</li>
  <li>Spiked GEO matrix: replica solution, rigorous derivation, BBP transition.</li>
  <li>Classical SGD theory</li>
  <li>Scaling limits of SGD in high-dimensions for single-index and two-layer neural networks: overparametrisation, information exponent.</li>
  <li>Diffusion models: introduction to stochastic processes and diffusion, speciation transition.</li>
</ul>

<h2 id="requirements">Requirements</h2>

<p>Basic probability theory, linear algebra and analysis. No background in statistical physics will be assumed.</p>

<h2 id="recommended-literature">Recommended literature</h2>

<ul>
  <li>Classical SGD theory, Chapter 5 in Francis’ <a href="https://www.di.ens.fr/~fbach/ltfp_book.pdf">book</a>.</li>
  <li>For one-pass SGD, Bruno’s <a href="https://brloureiro.github.io/assets/pdf/psl_week_notes_sgd.pdf">lecture notes</a>.</li>
</ul>

<h2 id="course-schedule">Course Schedule</h2>

<table>
  <thead>
    <tr>
      <th>Time</th>
      <th>Monday 04/03</th>
      <th>Tuesday 05/03</th>
      <th>Wednesday 06/03</th>
      <th>Thursday 07/03</th>
      <th>Friday 08/03</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>10:00 - 12:00</td>
      <td>Introduction to ML (Francis)</td>
      <td>Spiked GOE model I (Francis)</td>
      <td>SGD I (Francis)</td>
      <td>SGD III (Bruno)</td>
      <td>Diffusion II (Giulio)</td>
    </tr>
    <tr>
      <td>12:00 - 13:30</td>
      <td><strong>Lunch</strong></td>
      <td><strong>Lunch</strong></td>
      <td><strong>Lunch</strong></td>
      <td><strong>Lunch</strong></td>
      <td><strong>Lunch</strong></td>
    </tr>
    <tr>
      <td>13:30 - 15:30</td>
      <td>Introduction to Stat. Phys. (Giulio)</td>
      <td>Spiked GOE model II (Giulio)</td>
      <td>SGD II (Bruno)</td>
      <td>Diffusion I (Giulio)</td>
      <td> </td>
    </tr>
  </tbody>
</table>

  </main>
</body>
</html>
